# ğŸš€ å¿«é€Ÿå¼€å§‹ï¼šæ·»åŠ æ–°ç®—å­æµ‹è¯•

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®æä¾›äº†**å®Œå…¨æ¨¡å—åŒ–**çš„æ€§èƒ½æµ‹è¯•æ¡†æ¶ã€‚æ·»åŠ æ–°ç®—å­æ—¶ï¼Œä½ åªéœ€è¦å†™**æœ€å°‘çš„ä»£ç **ï¼š

- âœ… **è‡ªåŠ¨ç¼“å­˜æ¸…ç†**ï¼šæ¯æ¬¡æµ‹è¯•å‰è‡ªåŠ¨æ¸…ç©º NPU/CUDA ç¼“å­˜
- âœ… **è‡ªåŠ¨æ€§èƒ½æµ‹è¯•**ï¼šè‡ªåŠ¨æ‰§è¡Œ warmup å’Œå¤šæ¬¡æµ‹è¯•
- âœ… **è‡ªåŠ¨ç»Ÿè®¡è®¡ç®—**ï¼šè‡ªåŠ¨è®¡ç®— mean, median, std, min, max
- âœ… **è‡ªåŠ¨è¿›åº¦æ˜¾ç¤º**ï¼šæ¯ 10 æ¬¡æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
- âœ… **è‡ªåŠ¨ç»“æœä¿å­˜**ï¼šè‡ªåŠ¨ç”Ÿæˆ JSON æ ¼å¼ç»“æœæ–‡ä»¶

**ä½ åªéœ€è¦å®ç° 3 ä¸ªç®€å•æ–¹æ³•ï¼**

---

## ğŸ¯ æ·»åŠ æ–°ç®—å­çš„ 3 æ­¥æµç¨‹

### Step 1: å¤åˆ¶æ¨¡æ¿

```bash
# ä¾‹å¦‚ï¼šæ·»åŠ ä¸€ä¸ªåä¸º "relu" çš„æ–°ç®—å­
cp TEMPLATE_custom_test.py op/relu/relu_custom_test.py
```

### Step 2: æŸ¥æ‰¾æ›¿æ¢

åœ¨ `relu_custom_test.py` ä¸­ï¼š

```python
# å…¨å±€æ›¿æ¢ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰
{OPERATOR_NAME} â†’ relu
{OPERATOR_NAME_CAPITALIZED} â†’ Relu
```

ä½¿ç”¨ç¼–è¾‘å™¨çš„æŸ¥æ‰¾æ›¿æ¢åŠŸèƒ½ï¼š
- VSCode: `Ctrl/Cmd + H`
- Vim: `:%s/{OPERATOR_NAME}/relu/g`

### Step 3: å®ç° 3 ä¸ªæ–¹æ³•

#### 3.1 å­˜å‚¨è¾“å…¥ï¼ˆ`__init__`ï¼‰

```python
def __init__(self, x):
    super().__init__()
    self.x = x  # å­˜å‚¨ä½ çš„è¾“å…¥
```

#### 3.2 è¿è¡Œè‡ªå®šä¹‰ç®—å­ï¼ˆ`run_operator`ï¼‰

```python
def run_operator(self, *inputs):
    if inputs:
        return relu_custom.run_relu_custom(*inputs)
    return relu_custom.run_relu_custom(self.x)
```

#### 3.3 è¿è¡Œå‚è€ƒå®ç°ï¼ˆ`run_reference`ï¼‰

```python
def run_reference(self, *inputs):
    x_ref = inputs[0] if inputs else self.x.cpu()
    return torch.relu(x_ref)
```

#### 3.4 å‡†å¤‡æµ‹è¯•è¾“å…¥

```python
def test_relu_custom_ops(self):
    # å‡†å¤‡è¾“å…¥æ•°æ®
    x = torch.rand([1024, 1024], dtype=torch.float16).npu()

    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    perf_test = ReluPerformanceTest(x)
    perf_test.setup_device()

    # æ­£ç¡®æ€§æµ‹è¯•
    output = perf_test.run_operator()
    cpuout = torch.relu(x.cpu())
    self.assertRtolEqual(output, cpuout)

    # æ€§èƒ½æµ‹è¯•ï¼ˆè‡ªåŠ¨å®Œæˆï¼ï¼‰
    results = perf_test.measure_performance()
    perf_test.save_results(results)
```

### å®Œæˆï¼ğŸ‰

è¿è¡Œæµ‹è¯•ï¼š
```bash
python evaluater.py --op relu --runs 20
```

---

## ğŸ“š å®Œæ•´ç¤ºä¾‹å¯¹æ¯”

### âŒ æ—§æ–¹å¼ï¼ˆæ‰‹åŠ¨å®ç°ï¼Œ~100 è¡Œï¼‰

```python
# éœ€è¦æ‰‹å†™æ‰€æœ‰é€»è¾‘
for i in range(NUM_TRIALS):
    # æ‰‹åŠ¨æ¸…ç†ç¼“å­˜
    torch_npu.npu.empty_cache()
    torch_npu.npu.synchronize()

    # æ‰‹åŠ¨è®¡æ—¶
    start_event = torch_npu.npu.Event(enable_timing=True)
    end_event = torch_npu.npu.Event(enable_timing=True)
    start_event.record()
    output = relu_custom.run_relu_custom(x)
    end_event.record()
    torch_npu.npu.synchronize()

    # æ‰‹åŠ¨æ”¶é›†æ—¶é—´
    elapsed_time = start_event.elapsed_time(end_event)
    times.append(elapsed_time)

    # æ‰‹åŠ¨æ˜¾ç¤ºè¿›åº¦
    if (i + 1) % 10 == 0:
        print(f"Progress: {i+1}/{NUM_TRIALS}")

# æ‰‹åŠ¨è®¡ç®—ç»Ÿè®¡
mean = sum(times) / len(times)
median = sorted(times)[len(times)//2]
std = (sum((x - mean)**2 for x in times) / len(times)) ** 0.5
# ... æ›´å¤šç»Ÿè®¡ä»£ç 

# æ‰‹åŠ¨ä¿å­˜ç»“æœ
with open('timing_results.json', 'w') as f:
    json.dump({'mean': mean, 'median': median, ...}, f)
```

### âœ… æ–°æ–¹å¼ï¼ˆä½¿ç”¨æ¨¡å—ï¼Œ~30 è¡Œï¼‰

```python
class ReluPerformanceTest(BasePerformanceTest):
    def __init__(self, x):
        super().__init__()
        self.x = x

    def run_operator(self, *inputs):
        return relu_custom.run_relu_custom(self.x)

    def run_reference(self, *inputs):
        return torch.relu(self.x.cpu())

class TestCustomRelu(TestCase):
    def test_relu_custom_ops(self):
        x = torch.rand([1024, 1024], dtype=torch.float16).npu()
        perf_test = ReluPerformanceTest(x)
        perf_test.setup_device()

        # æ­£ç¡®æ€§
        output = perf_test.run_operator()
        cpuout = torch.relu(x.cpu())
        self.assertRtolEqual(output, cpuout)

        # æ€§èƒ½ï¼ˆè‡ªåŠ¨ï¼ï¼‰
        results = perf_test.measure_performance()
        perf_test.save_results(results)
```

**ä»£ç é‡å‡å°‘ 70%ï¼æ‰€æœ‰å¤æ‚é€»è¾‘éƒ½åœ¨ `BasePerformanceTest` ä¸­ï¼**

---

## ğŸ”§ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰ warmup æ¬¡æ•°

```python
perf_test = ReluPerformanceTest(x)
perf_test.num_warmup = 5  # é»˜è®¤ 3
```

### è‡ªå®šä¹‰å®¹å·®ï¼ˆtoleranceï¼‰

```python
passed, msg = perf_test.test_correctness(
    inputs=(x_npu,),
    reference_inputs=(x_cpu,),
    atol=1e-3,  # ç»å¯¹å®¹å·®
    rtol=1e-3   # ç›¸å¯¹å®¹å·®
)
```

### æ‰‹åŠ¨è®¡ç®—ç»Ÿè®¡

```python
times = [0.1, 0.2, 0.15, 0.18, 0.12]
stats = perf_test.calculate_statistics(times)
print(stats['statistics']['median'])  # è‡ªåŠ¨è®¡ç®—ä¸­ä½æ•°
```

---

## ğŸ“¦ BasePerformanceTest æä¾›çš„åŠŸèƒ½

| åŠŸèƒ½ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| è®¾å¤‡ç®¡ç† | `setup_device()` | è‡ªåŠ¨é€‰æ‹© NPU/CUDA/CPU |
| ç¼“å­˜æ¸…ç† | `clear_cache()` | æ¸…ç†è®¾å¤‡ç¼“å­˜ |
| åŒæ­¥ | `synchronize()` | åŒæ­¥è®¾å¤‡ |
| Warmup | `warmup(*inputs)` | é¢„çƒ­è¿è¡Œ |
| æ€§èƒ½æµ‹è¯• | `measure_performance(*inputs)` | å®Œæ•´æ€§èƒ½æµ‹è¯•æµç¨‹ |
| ç»Ÿè®¡è®¡ç®— | `calculate_statistics(times)` | è®¡ç®—æ‰€æœ‰ç»Ÿè®¡æŒ‡æ ‡ |
| ä¿å­˜ç»“æœ | `save_results(results, file)` | JSON æ ¼å¼ä¿å­˜ |
| æ­£ç¡®æ€§æµ‹è¯• | `test_correctness(...)` | è‡ªåŠ¨å¯¹æ¯”è¾“å‡º |

---

## ğŸ“Š è‡ªåŠ¨ç”Ÿæˆçš„ç»“æœæ ¼å¼

```json
{
  "raw_data": [0.15, 0.14, 0.16, ...],
  "statistics": {
    "mean": 0.147,
    "median": 0.145,
    "std": 0.009,
    "min": 0.135,
    "max": 0.171,
    "num_trials": 20
  }
}
```

---

## ğŸ“ å®é™…ä¾‹å­

### 1. ç®€å•ç®—å­ï¼ˆAddï¼‰

```python
class AddPerformanceTest(BasePerformanceTest):
    def __init__(self, x, y):
        super().__init__()
        self.x = x
        self.y = y

    def run_operator(self, *inputs):
        return add_custom.run_add_custom(self.x, self.y)

    def run_reference(self, *inputs):
        return torch.add(self.x.cpu(), self.y.cpu())
```

### 2. å¤æ‚ç®—å­ï¼ˆMatmul with Biasï¼‰

```python
class MatmulPerformanceTest(BasePerformanceTest):
    def __init__(self, a, b, bias):
        super().__init__()
        self.a = a
        self.b = b
        self.bias = bias

    def run_operator(self, *inputs):
        return matmul_custom.run_matmul_custom(self.a, self.b, self.bias)

    def run_reference(self, *inputs):
        a_ref = self.a.cpu().type(torch.float32)
        b_ref = self.b.cpu().type(torch.float32)
        return torch.matmul(a_ref, b_ref) + self.bias.cpu()
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q: å¦‚ä½•è°ƒæ•´æµ‹è¯•æ¬¡æ•°ï¼Ÿ

A: ä½¿ç”¨ `--runs` å‚æ•°ï¼š
```bash
python evaluater.py --op your_op --runs 50
```

### Q: ç¼“å­˜æ¸…ç†å½±å“æ€§èƒ½å—ï¼Ÿ

A: ä¼šç•¥å¾®å¢åŠ æµ‹è¯•æ—¶é—´ï¼Œä½†èƒ½ä¿è¯æµ‹è¯•å…¬å¹³æ€§ã€‚ç¼“å­˜æ¸…ç†åªåœ¨æµ‹è¯•å‰æ‰§è¡Œï¼Œä¸è®¡å…¥æ€§èƒ½æ—¶é—´ã€‚

### Q: æ”¯æŒ CPU æµ‹è¯•å—ï¼Ÿ

A: å®Œå…¨æ”¯æŒï¼`BasePerformanceTest` ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨åˆé€‚çš„è®¡æ—¶æ–¹æ³•ã€‚

### Q: å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰ç»Ÿè®¡æŒ‡æ ‡ï¼Ÿ

A: é‡å†™ `calculate_statistics` æ–¹æ³•ï¼š
```python
def calculate_statistics(self, times):
    results = super().calculate_statistics(times)
    # æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡
    results['statistics']['p95'] = sorted(times)[int(len(times)*0.95)]
    return results
```

---

## ğŸ“ æ€»ç»“

ä½¿ç”¨æ¨¡å—åŒ–æ¡†æ¶ï¼Œä½ åªéœ€è¦ï¼š

1. âœ… å¤åˆ¶æ¨¡æ¿
2. âœ… æ›¿æ¢ç®—å­åç§°
3. âœ… å®ç° 3 ä¸ªæ–¹æ³•ï¼ˆå­˜å‚¨è¾“å…¥ã€è¿è¡Œç®—å­ã€è¿è¡Œå‚è€ƒï¼‰

**å°±è¿™æ ·ï¼** ğŸ‰

æ‰€æœ‰å¤æ‚çš„åŠŸèƒ½ï¼ˆç¼“å­˜æ¸…ç†ã€æ€§èƒ½æµ‹è¯•ã€ç»Ÿè®¡ã€ä¿å­˜ï¼‰éƒ½æ˜¯è‡ªåŠ¨çš„ï¼

---

**Happy Testing!** ğŸš€
